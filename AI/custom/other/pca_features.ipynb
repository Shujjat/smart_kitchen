{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying dimensionality reduction to 820'676 image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:04:41.204640Z",
     "start_time": "2018-11-09T21:04:39.072390Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "# coding=utf-8\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables\n",
    "from IPython.display import HTML, display\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.set_printoptions(threshold=np.nan) # prints the whole nparray no matter the shape of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing image features with pytables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T10:49:37.878290Z",
     "start_time": "2018-11-08T10:49:37.338598Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file_original_1 = tables.open_file('models/vgg16_bottleneck_features.hdf5', mode='r')\n",
    "features_original_1 = hdf5_file_original_1.root.img_features # Sparse data, mostly zeros\n",
    "images_original_1 = hdf5_file_original_1.root.img_paths\n",
    "\n",
    "hdf5_file_original_2 = tables.open_file('models/vgg16_bottleneck_features_02.hdf5', mode='r')\n",
    "features_original_2 = hdf5_file_original_2.root.img_features # Sparse data, mostly zeros\n",
    "images_original_2 = hdf5_file_original_2.root.img_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path for the new, third table containg merged image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T20:59:38.279403Z",
     "start_time": "2018-11-08T20:59:38.276406Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_path_pca = 'models/vgg16_bottleneck_features_PCA.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new tables file which contains merged image paths and merged image features from both preexisting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:07:29.133072Z",
     "start_time": "2018-11-08T11:07:29.077253Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file_pca = tables.open_file(hdf5_path_pca, mode='w')\n",
    "\n",
    "images_original_3 = hdf5_file_pca.create_array(hdf5_file_pca.root,\n",
    "                                               'img_paths', atom=images_original_1.atom,\n",
    "                                               shape=(images_original_1.nrows + images_original_2.nrows,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining image paths from first file and second file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:08:26.784267Z",
     "start_time": "2018-11-08T11:08:25.855296Z"
    }
   },
   "outputs": [],
   "source": [
    "images_original_3[:images_original_1.nrows] = images_original_1[:]\n",
    "images_original_3[images_original_1.nrows:] = images_original_2[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flushing pending data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:08:49.465786Z",
     "start_time": "2018-11-08T11:08:49.446484Z"
    }
   },
   "outputs": [],
   "source": [
    "images_original_3.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features_pca will contain all raw image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:19:03.210811Z",
     "start_time": "2018-11-08T11:19:03.102755Z"
    }
   },
   "outputs": [],
   "source": [
    "data_shape = (0, 4096)\n",
    "img_dtype = tables.Float32Atom()\n",
    "\n",
    "features_pca = hdf5_file_pca.create_earray(hdf5_file_pca.root, 'img_features', img_dtype, shape=data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:23:23.062663Z",
     "start_time": "2018-11-08T11:20:01.513712Z"
    }
   },
   "outputs": [],
   "source": [
    "features_pca.append(features_original_1.read())\n",
    "features_pca.flush()\n",
    "\n",
    "ft_2_np = features_original_2.read()\n",
    "features_original_1.append(ft_2_np)\n",
    "features_pca.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T11:26:12.625970Z",
     "start_time": "2018-11-08T11:26:12.619474Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file_pca.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T20:59:56.715921Z",
     "start_time": "2018-11-08T20:59:56.680799Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file_pca = tables.open_file(hdf5_path_pca, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T20:59:57.865327Z",
     "start_time": "2018-11-08T20:59:57.861871Z"
    }
   },
   "outputs": [],
   "source": [
    "features_pca = hdf5_file_pca.root.img_features\n",
    "images_pca = hdf5_file_pca.root.img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:00:00.441655Z",
     "start_time": "2018-11-08T21:00:00.436724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820676"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pca.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis\n",
    "\n",
    "The image features take up **12.52 GB** (820'676*4'096*32)/(8*1'024*1'024*1'024) which is simply to big to load it completely into ram. Instead, sklearn provides us with an altered pca implementation enabling us to calculate the eigenvalues batchwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T19:47:15.410741Z",
     "start_time": "2018-11-08T19:03:12.259754Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [44:02<00:00, 269.60s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n = features_pca.shape[0] # how many rows we have in the dataset\n",
    "chunk_size = 82000 # how many rows we feed to IPCA at a time, the divisor of n\n",
    "ipca = IncrementalPCA(n_components=512, batch_size=41000)\n",
    "\n",
    "for i in tqdm(range(0, n//chunk_size)):\n",
    "    ipca.partial_fit(features_pca[i*chunk_size : (i+1)*chunk_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T19:48:51.815290Z",
     "start_time": "2018-11-08T19:48:48.885130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncrementalPCA(batch_size=41000, copy=True, n_components=512, whiten=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipca.partial_fit(features_pca[820000:]) # 820'000 = chunk_size*(n//chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the IncrementalPCA(batch_size=41000, copy=True, n_components=512, whiten=False) object on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T19:49:24.617940Z",
     "start_time": "2018-11-08T19:49:24.435120Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(ipca, open('models/sklearn_ipca_object.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:15:52.210226Z",
     "start_time": "2018-11-08T21:15:52.206767Z"
    }
   },
   "source": [
    "Loading it into mem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:04:48.419288Z",
     "start_time": "2018-11-09T21:04:46.914218Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_in = open(\"models/sklearn_ipca_object.p\",\"rb\")\n",
    "ipca = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our final hdf5 file\n",
    "#### Path for the new, third table containg reduced image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:55:07.178815Z",
     "start_time": "2018-11-08T21:55:07.175882Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_path_ipca = 'models/vgg16_bottleneck_features_IPCA.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:28:30.969538Z",
     "start_time": "2018-11-08T21:28:30.695549Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file_ipca = tables.open_file(hdf5_path_ipca, mode='w') # Create new hdf5 file\n",
    "\n",
    "# Takes up 61.6 MB on disk\n",
    "hdf5_file_ipca.create_array(hdf5_file_ipca.root, 'img_paths', images_pca.read()) # Create array for image paths\n",
    "\n",
    "data_shape = (0, 512) # Shape is now 512!\n",
    "img_dtype = tables.Float32Atom()\n",
    "\n",
    "# Create enlargeable array for image features\n",
    "features_ipca = hdf5_file_ipca.create_earray(hdf5_file_ipca.root, 'img_features', img_dtype, shape=data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:31:29.671832Z",
     "start_time": "2018-11-08T21:28:41.114509Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:07<01:06,  7.44s/it]\u001b[A\n",
      "100%|██████████| 10/10 [02:48<00:00, 17.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# PCA.transform actually returns float64 rather than float32\n",
    "\n",
    "n = features_pca.shape[0] # how many rows we have in the dataset\n",
    "chunk_size = 82000 # how many rows we feed to IPCA at a time, the divisor of n\n",
    "\n",
    "for i in tqdm(range(0, n//chunk_size)):\n",
    "    features_ipca.append(ipca.transform(features_pca[i*chunk_size : (i+1)*chunk_size]))\n",
    "    \n",
    "features_ipca.append(ipca.transform(features_pca[820000:])) # 820'000 = chunk_size*(n//chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:31:49.432505Z",
     "start_time": "2018-11-08T21:31:49.428680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820676, 512)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ipca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flushing and closing our pytable to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:33:00.657219Z",
     "start_time": "2018-11-08T21:33:00.607304Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file_ipca.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing image features for nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:04:55.750510Z",
     "start_time": "2018-11-09T21:04:55.743428Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_path_ipca = 'models/vgg16_bottleneck_features_IPCA.hdf5'\n",
    "hdf5_file_ipca = tables.open_file(hdf5_path_ipca, mode='r') # Create new hdf5 file\n",
    "features_ipca = hdf5_file_ipca.root.img_features\n",
    "images = hdf5_file_ipca.root.img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:04:57.006173Z",
     "start_time": "2018-11-09T21:04:56.969670Z"
    }
   },
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "# nmslib default params for now\n",
    "\n",
    "# Number of neighbors\n",
    "K = 18\n",
    "# Set index parameters\n",
    "# These are the most important ones\n",
    "M = 15\n",
    "efC = 100\n",
    "num_threads = 4\n",
    "index_time_params = {'M': M, 'indexThreadQty': num_threads, 'efConstruction': efC, 'post' : 0}\n",
    "space_name='l2'\n",
    "efS = 100\n",
    "query_time_params = {'efSearch': efS}\n",
    "index_ann = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:04:57.671984Z",
     "start_time": "2018-11-09T21:04:57.665780Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_ann_index(bin_PATH='models/image_features_pca_nmslib_index.bin'):\n",
    "    global index_ann\n",
    "    # Intitialize the library, specify the space, the type of the vector and add data points \n",
    "    index_ann = nmslib.init(method='hnsw', space=space_name, data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "    # Re-load the index and re-run queries\n",
    "    index_ann.loadIndex(bin_PATH)\n",
    "    # Setting query-time parameters and querying\n",
    "    print('Setting query-time parameters', query_time_params)\n",
    "    index_ann.setQueryTimeParams(query_time_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:05:04.802944Z",
     "start_time": "2018-11-09T21:04:58.262227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting query-time parameters {'efSearch': 100}\n"
     ]
    }
   ],
   "source": [
    "init_ann_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T22:11:28.455456Z",
     "start_time": "2018-11-08T22:11:28.447470Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_ann_index(bin_PATH):\n",
    "    global index_ann\n",
    "    # Intitialize the library, specify the space, the type of the vector and add data points \n",
    "    index_ann = nmslib.init(method='hnsw', space=space_name, data_type=nmslib.DataType.DENSE_VECTOR) \n",
    "    index_ann.addDataPointBatch(features_ipca.read())\n",
    "    index_ann.createIndex(index_time_params, print_progress=True)\n",
    "    index_ann.saveIndex(bin_PATH)\n",
    "    # Setting query-time parameters and querying\n",
    "    print('Setting query-time parameters', query_time_params)\n",
    "    index_ann.setQueryTimeParams(query_time_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T22:18:09.606048Z",
     "start_time": "2018-11-08T22:11:29.888177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting query-time parameters {'efSearch': 100}\n"
     ]
    }
   ],
   "source": [
    "create_ann_index('models/image_features_pca_nmslib_index.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
